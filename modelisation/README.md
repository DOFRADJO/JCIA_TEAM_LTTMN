
# Projet JCIA Hackathon 2025 - Proc√©d√© de classification de la qualit√© des prunes africaines

## üìå Objectif
Ce notebook Jupyter a √©t√© d√©velopp√© dans le cadre du **JCIA Hackathon 2025** pour √©valuer la qualit√© et d√©tecter les d√©fauts des prunes africaines √† l'aide de techniques de deep learning. Il utilise un mod√®le de classification d'images pour analyser un jeu de donn√©es de prunes, class√©es selon leur √©tat (qualit√© saine vs. d√©fectueuse).

---

## üìú Fichiers de code
   *  JCIA_HACKATON_2025_Final.ipynb (version jupyter)
   *  JCIA_HACKATON_2025_Final.pdf
   *  JCIA_HACKATON_2025_Final.html
   *  JCIA_HACKATON_2025_Final.py

---

## üìÇ Structure du projet
### Donn√©es
- **Source** : Dataset Kaggle [`african-plums-quality-and-defect-assessment-data`](https://www.kaggle.com/arnaudfadja/african-plums-quality-and-defect-assessment-data).
- **Contenu** :
  - Images organis√©es en sous-dossiers par classe (ex: `defect`, `fresh`, `rotten`).
  - Chemin d'acc√®s : `/kaggle/input/african-plums-quality-and-defect-assessment-data/african_plums_dataset/african_plums/`.

### Biblioth√®ques utilis√©es
- **Kaggle** : `pip install kagglehub`
- **Data Processing** : `numpy`, `pandas`, `matplotlib`, `seaborn`, `PIL`.
- **Deep Learning** : `torch`, `torchvision`, `timm`, `transformers` (ViT).
- **Utilitaires** : `os`, `shutil`, `tqdm`, `sklearn` pour les m√©triques.

Voir le fichier `requirements_models.txt`

---

## üöÄ √âtapes cl√©s du notebook
1. **Importation des donn√©es et visualisations**  
   - T√©l√©chargement du dataset Kaggle via `kagglehub`.
   - Affichage d'√©chantillons d'images de 6 classes diff√©rentes.
   - Visualisation du nombre d'images par dossiers

2. **Pr√©paration des donn√©es** 
   - Copie double de 90% et 10% des donn√©es image dans 2 autres dossiers contenues dans les repertoires `dossier_1 et dossier_2`: `train_val_temp_(1/2)` et `test_(1/2)` respectivement, chacun contenant les 6 classes d'image
   - transformation des classes de tout les repertoires du dossier `model_1` en 3 classes (`defective, unaffected et unripe`).
   - transformatiions et data augmentation et √©quilibrage des classes de chaques sous dossiers de `dossier_1` et `dossier_2`

3. **Architecture du mod√®le**
   - **Choix d'un mod√®le** : **ConvNeXt v2** via `transformers.AutoImageProcessor` pour les 2 sous mod√®les de l'architecture.
   - **Comment fonctionne l'algorithme ConvNeXt v2** : voir le fichier `ConvNext_v2.pdf` du repertoire.
   - **‚úÖ Pourquoi ConvNeXt V2 ?** : ConvNeXt V2 est une architecture **convolutionnelle moderne**, optimis√©e pour offrir la performance des Transformers (ViT), tout en conservant les avantages fondamentaux des CNNs classiques.
   - **‚öôÔ∏è Avantages dans ce contexte sp√©cifique** : 
| Avantage | D√©tail |
|---------|--------|
| üìâ **Robuste aux petits datasets** | Gr√¢ce √† ses inducteurs de biais (localit√©, translational equivariance), ConvNeXt V2 apprend efficacement avec peu d‚Äôimages. |
| üöÄ **Entra√Ænement plus rapide et stable** | Moins sensible √† l‚Äôinstabilit√© que les architectures Transformer (ViT), surtout sans pr√©entra√Ænement. |
| üß† **Excellente g√©n√©ralisation** | Capable de bien se g√©n√©raliser sur des donn√©es de type visuel avec peu d‚Äôoverfitting. |
| üîÑ **Compatible avec le transfert learning** | Peut √™tre initialis√© avec des poids pr√©entra√Æn√©s sur ImageNet pour des performances accrues. |
| ü§ô **Facile √† int√©grer dans les pipelines existants** | API support√©e via PyTorch, `timm`, et autres frameworks. |

4. **Entra√Ænement, √©valuation et test**  
   - Utilisation de `DataLoader` pour le chargement par lots.
   - **M√©triques** : Accuracy, precission, recall, f1_score, matrice de confusion
   - **R√©gularisation** : Early stopping, label smoothing, dropout
   - **Optimisation** : AdamW (Adaptive Moment Estimation with Weight Decay), weight decay
   - Calcul des m√©triques de performance (`classification_report (accuracy (g√©n√©ral et par classe), precision, recall, f1-score)`, `confusion_matrix`).

---

## üìä R√©sultats
- Visualisation des pr√©dictions et analyse des erreurs.
- Matrice de confusion pour √©valuer la pr√©cision par classe.
- Rapport de classification incluant **pr√©cision**, **rappel**, et **F1-score**.

---

## üíª Ex√©cution du code
### Pr√©requis
- Compte Kaggle pour acc√©der au dataset.
- Librairies Python list√©es dans les cellules d'import.

### √âtapes
1. T√©l√©chargez le dataset Kaggle via l'API `kagglehub`.
2. Ex√©cutez les cellules dans l'ordre pour :
   - Charger les donn√©es.
   - Entra√Æner le mod√®le.
   - G√©n√©rer les visualisations et m√©triques.

---

## üîç Insights
- **D√©fi principal** : D√©s√©quilibre des classes.
- **Optimisation** : Fine-tuning du ConvNeXt v2 et augmentation + √©quilibrage des donn√©es pour am√©liorer la g√©n√©ralisation.

---

## ‚úç Auteurs
√âquipe du JCIA Hackathon 2025 : **QuadraMind**

