
# Projet JCIA Hackathon 2025 - Classification de la qualit√© des prunes africaines

## üìå Objectif
Ce notebook Jupyter a √©t√© d√©velopp√© dans le cadre du **JCIA Hackathon 2025** pour √©valuer la qualit√© et d√©tecter les d√©fauts des prunes africaines √† l'aide de techniques de deep learning. Il utilise un mod√®le de classification d'images pour analyser un jeu de donn√©es de prunes, class√©es selon leur √©tat (qualit√© saine vs. d√©fectueuse).

---

## üìÇ Structure du projet
### Donn√©es
- **Source** : Dataset Kaggle [`african-plums-quality-and-defect-assessment-data`](https://www.kaggle.com/arnaudfadja/african-plums-quality-and-defect-assessment-data).
- **Contenu** :
  - Images organis√©es en sous-dossiers par classe (ex: `defect`, `fresh`, `rotten`).
  - Chemin d'acc√®s : `/kaggle/input/african-plums-quality-and-defect-assessment-data/african_plums_dataset/african_plums/`.

### Biblioth√®ques utilis√©es
- **Data Processing** : `numpy`, `pandas`, `matplotlib`, `seaborn`, `PIL`.
- **Deep Learning** : `torch`, `torchvision`, `timm`, `transformers` (ViT).
- **Utilitaires** : `os`, `shutil`, `tqdm`, `sklearn` pour les m√©triques.

---

## üöÄ √âtapes cl√©s du notebook
1. **Importation des donn√©es**  
   - T√©l√©chargement du dataset Kaggle via `kagglehub`.
   - Exploration des r√©pertoires d'images (`train/` , `test/` et `val/`).

2. **Visualisation des donn√©es**  
   - Affichage d'√©chantillons d'images de 6 classes diff√©rentes.

3. **Pr√©paration des donn√©es**  
   - Utilisation de `torchvision.datasets.ImageFolder` pour structurer les donn√©es en 2 groupes :
        - **model_1** : contient les train, val et test de 3 classes d'images `defective, unaffected et unripe` (unaffective √©tant un m√©lange √©quilibr√© des autres classes).
        - **model_2** : contient les train, val et test de 4 classes d'images `unripe, cracked, rotten et spotted`.
   - Transformation, augmentation et √©quilibrage des images avec `transforms` (redimensionnement, normalisation, ...) en fonction du sous mod√®le.

4. **Architecture du mod√®le**  
   - Choix d'un mod√®le **ConvNeXt v2** via `transformers.AutoImageProcessor` pour les 2 sous mod√®les de l'architecture.
   - Configuration de l'entra√Ænement avec `torch` (optimiseur, fonctions de perte).
   - 

5. **Entra√Ænement, √©valuation et test**  
   - Utilisation de `DataLoader` pour le chargement par lots.
   - Calcul des m√©triques de performance (`classification_report (accuracy (g√©n√©ral et par classe), precision, recall, f1-score)`, `confusion_matrix`).

---

## üìä R√©sultats
- Visualisation des pr√©dictions et analyse des erreurs.
- Matrice de confusion pour √©valuer la pr√©cision par classe.
- Rapport de classification incluant **pr√©cision**, **rappel**, et **F1-score**.

---

## üíª Ex√©cution du code
### Pr√©requis
- Compte Kaggle pour acc√©der au dataset.
- Librairies Python list√©es dans les cellules d'import.

### √âtapes
1. T√©l√©chargez le dataset Kaggle via l'API `kagglehub`.
2. Ex√©cutez les cellules dans l'ordre pour :
   - Charger les donn√©es.
   - Entra√Æner le mod√®le.
   - G√©n√©rer les visualisations et m√©triques.

---

## üîç Insights
- **D√©fi principal** : D√©s√©quilibre des classes (ex: plus d'images de prunes saines que d√©fectueuses).
- **Optimisation** : Fine-tuning du ConvNeXt v2 et augmentation + √©quilibrage des donn√©es pour am√©liorer la g√©n√©ralisation.

---

## Auteurs
√âquipe du JCIA Hackathon 2025.

