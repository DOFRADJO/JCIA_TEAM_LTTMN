# -*- coding: utf-8 -*-
"""JCIA_HACKATON_2025_Final (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q80k6MCSL1UNXuCqmYA6OqyrCoai_kRy
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
import os

arnaudfadja_african_plums_quality_and_defect_assessment_data_path = kagglehub.dataset_download('arnaudfadja/african-plums-quality-and-defect-assessment-data')

print('Data source import complete.')
print(f"Le dataset a √©t√© t√©l√©charg√© dans le dossier : {arnaudfadja_african_plums_quality_and_defect_assessment_data_path}")

# Vous pouvez maintenant lister le contenu du dossier :
if arnaudfadja_african_plums_quality_and_defect_assessment_data_path:
    for item in os.listdir(arnaudfadja_african_plums_quality_and_defect_assessment_data_path):
        print(f"- {item}")

    # Si vous savez qu'il y a un sous-dossier 'train' par exemple :
    train_folder = os.path.join(arnaudfadja_african_plums_quality_and_defect_assessment_data_path, 'train')
    if os.path.isdir(train_folder):
        print(f"\nContenu du dossier 'train' :")
        for item in os.listdir(train_folder):
            print(f"-- {item}")

"""# 1) Importation des libreries et biblioth√®ques"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
from PIL import Image
import pandas as pd
import seaborn as sns
import random
import shutil
from pathlib import Path
from tqdm import tqdm
import torch
from torchvision import datasets, transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import Subset, Dataset, DataLoader
from torch import nn, optim
from transformers import AutoImageProcessor, ViTForImageClassification
from torch import nn, optim
import timm
from timm import create_model
from threading import Thread
from sklearn.metrics import classification_report, confusion_matrix
import torch.nn.functional as F

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

#for dirname, _, filenames in os.walk('/kaggle/input/'):
 #   for filename in filenames:
  #      print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

#elements = os.listdir('/kaggle/working')
#print(elements)

"""# 2) Chargement des donn√©es"""

#repertoire racine
path = arnaudfadja_african_plums_quality_and_defect_assessment_data_path + '/african_plums_dataset'

# Chemin du dossier contenant les sous-dossiers
dossier_images = os.path.join(path, 'african_plums')

# Obtenir les sous-dossiers
classes = [os.path.join(dossier_images, nom) for nom in os.listdir(dossier_images) if os.path.isdir(os.path.join(dossier_images, nom))]

# Cr√©er une figure avec 1 ligne et 6 colonnes
fig, axes = plt.subplots(1, 6, figsize=(15, 5))

# Afficher une image de chaque dossier
for ax, dossier in zip(axes, classes[:6]):  # Limiter √† 6 dossiers
    # Charger la premi√®re image du dossier
    images = os.listdir(dossier)
    if images:
        image_path = os.path.join(dossier, images[55])  # Prendre la premi√®re image
        img = Image.open(image_path)
        ax.imshow(img)
        ax.axis('off')  # Masquer les axes
        ax.set_title(os.path.basename(dossier))  # Titre avec le nom du dossier

# Afficher la figure
plt.tight_layout()
plt.show()

# Chemin du dossier contenant le fichier CSV
nom_fichier = 'organized_plums_data_new.csv'

# Construire le chemin complet du fichier
chemin_fichier = os.path.join(path, nom_fichier)

# Charger le fichier CSV dans un DataFrame
df = pd.read_csv(chemin_fichier)

df.sample(10)

df.shape

df.columns = ['Image_Id', 'Label', 'class']
df.sample(10)

df.info()

df.isna().sum(axis=0)

df.duplicated().sum()
print(f"Nombre total de valeurs dupliqu√©es : {df.duplicated().sum()}")

print("Nombre total d'image pour chaque type de classe :")
df.groupby('class').size()

df.groupby('Label')['class'].agg(lambda x: list(set(x))).reset_index()

# Initialiser les listes pour les noms de dossiers et le nombre d'images
noms_dossiers = []
nombre_images = []

# Compter le nombre d'images dans chaque sous-dossier
for nom in os.listdir(dossier_images):
    chemin_dossier = os.path.join(dossier_images, nom)
    if os.path.isdir(chemin_dossier):
        images = [f for f in os.listdir(chemin_dossier) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]
        noms_dossiers.append(nom)
        nombre_images.append(len(images))

# D√©terminer les couleurs des barres
couleurs = ['red' if nom in ['rotten', 'bruised', 'spotted', 'cracked'] else 'blue' if nom == 'unripe' else 'green' for nom in noms_dossiers]

# Cr√©er l'histogramme
plt.figure(figsize=(10, 6))
ax = plt.bar(noms_dossiers, nombre_images, color=couleurs)

# Ajouter des √©tiquettes sur les barres
plt.bar_label(ax)

# Configurer les axes et le titre
plt.xlabel('Classes')
plt.ylabel('Nombre d\'images')
plt.title('Nombre d\'images dans chaque dossier')
plt.xticks(rotation=45)
plt.tight_layout()  # Ajuster l'espacement
# Ajouter la l√©gende
plt.legend(
    handles=[
        plt.Rectangle((0, 0), 1, 1, color='red', label='D√©fective (rotten, bruised, spotted, cracked)'),
        plt.Rectangle((0, 0), 1, 1, color='blue', label='Unripe (unripe)'),
        plt.Rectangle((0, 0), 1, 1, color='green', label='Good (unaffected)')
    ],
    title='Cat√©gories'
)
plt.show()

"""En r√©sum√©, les classes **spotted, cracked, rotten et bruised** fond tous parties de la classe **defective**, et la classe **good** se confond avec la classe **unaffected**. Il est aussi √† noter que les donn√©es sont tr√®s d√©s√©quilibr√©s mais nous allons g√©rer cela dans les √©tapes suivantes avec **la data augmentation**.

# 3) Pr√©traitement des images
"""

# Petite fonctions pour conna√Ætre le nombre et les noms d'√©lements dans un dossier
def compter_elements(chemin, display_element=False):
    try:
        # Lister les √©l√©ments dans le r√©pertoire
        elements = os.listdir(chemin)
        # Compter le nombre d'√©l√©ments
        nombre_elements = len(elements)

        if display_element:
            print(f"√âl√©ments du r√©pertoire : {elements}")

        print(f"Nombre d'√©l√©ments : {nombre_elements}")

    except FileNotFoundError:
        return "Le chemin sp√©cifi√© n'existe pas."
    except PermissionError:
        return "Acc√®s refus√© au chemin sp√©cifi√©."

compter_elements(path, True)

path

"""Le principe g√©n√©ral pour bien organiser nos donn√©es est le suivant :

1.   Copier l'ensemble de donn√©es dans un dossier **data** (data_use) situer dans notre repertoire de travail (work_path) et y ajouter 2 dossiers **model_1 et model_2** (folder_model_1 et folder_model_2) qui contiendront les ensembles de donn√©es de chaque model.
2.   A l'int√©rieur de chaque dossier de model, on craira d'abord 2 dossiers **train_val_temp_1(ou 2) et test_1(ou 2)** qui contiendront respectivement **90% et 10%** des donn√©es de chaque classe contenues dans le dossier data (tout en conservant leurs classes). C-a-d 90% de spotted, 90% de enripe, ...
3.   Consernant uniquement les dossiers test_1 et train_val_temp_1, on rassemble toutes les images contenues dans les dossiers **spotted, cracked, rotte, et bruised** dans un seul dossier du nom de **defective** afin d'avoir 3 classes.
4.   Effectuer la data augmentation sur les donn√©es de test tout en √©quilibrant les diff√©rentes classes de sorte que les classes minoritaires aient le m√™me nombre d'image que la classe majoritaire.
5.   Effectuer aussi la data augmentation sur les dossier train_val_temp puis les diviser en dossiers **train et val** contenant respectivement **80% et 20% des 90% des images du dossier train_val_temp**.

## 3.1) Configuration des chemins
"""

# D√©finir les chemins
work_path = os.getcwd()
path_data = os.path.join(path, 'african_plums')  # Dossier source
data_use = os.path.join(work_path, '/data')            # Dossier cible
folder_model_1 = os.path.join(work_path, '/model_1')
folder_model_2 = os.path.join(work_path, '/model_2')
train_val_temp_1 = os.path.join(folder_model_1, 'train_val_temp_1')
train_val_temp_2 = os.path.join(folder_model_2, 'train_val_temp_2')
test_1 = os.path.join(folder_model_1, 'test_1')
test_2 = os.path.join(folder_model_2, 'test_2')

# Fonction pour cr√©er un dossier (et le recr√©er s'il existe)
def create_folder(path):
    if os.path.exists(path):
        shutil.rmtree(path)
        print(f"üóëÔ∏è Dossier existant supprim√© : {path}")
    os.makedirs(path)
    print(f"üìÅ Nouveau dossier cr√©√© : {path}")

# Cr√©ation des dossiers n√©cessaires
print("üîß Cr√©ation des dossiers requis...")
create_folder(data_use)
create_folder(folder_model_1)
create_folder(folder_model_2)
create_folder(train_val_temp_1)
create_folder(train_val_temp_2)
create_folder(test_1)
create_folder(test_2)

# Fonction pour copier les fichiers/dossiers avec barre de progression
def copy_with_progress(src, dst):
    if not os.path.exists(dst):
        os.makedirs(dst)

    items = os.listdir(src)
    print(f"\nüì¶ Copie de {len(items)} √©l√©ments de '{src}' vers '{dst}'...\n")

    for item in tqdm(items, desc="üì§ Copie en cours", unit="√©l√©ment"):
        s = os.path.join(src, item)
        d = os.path.join(dst, item)
        if os.path.isdir(s):
            shutil.copytree(s, d)
        else:
            shutil.copy2(s, d)

# Lancer la copie
copy_with_progress(path_data, data_use)

print("\n‚úÖ Op√©ration termin√©e avec succ√®s ! Tous les fichiers ont √©t√© copi√©s üéâ")

compter_elements(work_path, True)
compter_elements(data_use, True)
compter_elements(folder_model_1, True)
compter_elements(folder_model_2, True)

"""## 3.2) S√©paration des images dans les dossiers model_1 et model_2



"""

# Classes √† traiter
classes_model_1 = ['spotted', 'cracked', 'bruised', 'unaffected', 'unripe', 'rotten']
classes_model_2 = ['spotted', 'cracked', 'bruised', 'rotten']

def split_images(source_root, target_train, target_test, classes, ratio=0.1):
    for class_name in tqdm(classes, desc="üîç Traitement des classes", unit="classe"):
        source_class_dir = os.path.join(source_root, class_name)
        images = os.listdir(source_class_dir)
        random.shuffle(images)

        test_count = int(len(images) * ratio)
        test_images = images[:test_count]
        train_images = images[test_count:]

        # Dossiers cibles
        class_train_dir = os.path.join(target_train, class_name)
        class_test_dir = os.path.join(target_test, class_name)

        os.makedirs(class_train_dir, exist_ok=True)
        os.makedirs(class_test_dir, exist_ok=True)

        # Copier les images de test
        for img in test_images:
            src = os.path.join(source_class_dir, img)
            dst = os.path.join(class_test_dir, img)
            shutil.copy2(src, dst)

        # Copier les images de train_val
        for img in train_images:
            src = os.path.join(source_class_dir, img)
            dst = os.path.join(class_train_dir, img)
            shutil.copy2(src, dst)

        print(f"üìÇ Classe '{class_name}': {len(train_images)} entra√Ænement/val | {len(test_images)} test")

# S√©paration pour le model_1
print("\nüöÄ S√©paration pour le model_1")
split_images(data_use, train_val_temp_1, test_1, classes_model_1)

# S√©paration pour le model_2
print("\nüöÄ S√©paration pour le model_2")
split_images(data_use, train_val_temp_2, test_2, classes_model_2)

print("\n‚úÖ S√©paration termin√©e avec succ√®s pour les deux mod√®les ! üéâ")

compter_elements(train_val_temp_1, True)
compter_elements(test_1, True)
compter_elements(train_val_temp_2, True)
compter_elements(test_2, True)

"""## 3.3) Cr√©ation des classes 'defective'"""

# Dossiers √† fusionner
defective_classes = ['spotted', 'cracked', 'bruised', 'rotten']

# Chemins vers les sous-dossiers de model_1
#train_val_temp_1 = os.path.join('model_1', 'train_val_temp_1')
#test_1 = os.path.join('model_1', 'test_1')

def merge_to_defective(root_dir):
    defective_path = os.path.join(root_dir, 'defective')
    os.makedirs(defective_path, exist_ok=True)

    # Liste dynamique des classes √† fusionner √† partir du contenu r√©el
    class_names = os.listdir(root_dir)
    for class_name in class_names:
        class_path = os.path.join(root_dir, class_name)

        # On ne fusionne que les classes "d√©fectueuses"
        if class_name in ['spotted', 'cracked', 'bruised', 'rotten'] and os.path.isdir(class_path):
            images = os.listdir(class_path)
            for img in tqdm(images, desc=f"üì¶ Fusion '{class_name}' ‚Üí 'defective' ({root_dir})", unit="img"):
                src = os.path.join(class_path, img)
                dst = os.path.join(defective_path, img)

                # Renommage si doublon
                if os.path.exists(dst):
                    base, ext = os.path.splitext(img)
                    count = 1
                    while os.path.exists(dst):
                        dst = os.path.join(defective_path, f"{base}_{count}{ext}")
                        count += 1

                shutil.move(src, dst)

            # Supprimer le dossier une fois fusion termin√©
            shutil.rmtree(class_path)
            print(f"üóëÔ∏è Supprim√© : {class_path}")

        elif class_name in ['unaffected', 'unripe']:
            print(f"‚úÖ Conserv√© : {class_name}")

    print(f"\n‚úÖ Structure finale dans {root_dir} : {os.listdir(root_dir)}")

# Appliquer pour train_val_temp_1 et test_1
print("\nüöÄ Fusion des classes d√©fectueuses dans 'train_val_temp_1'")
merge_to_defective(train_val_temp_1)

print("\nüöÄ Fusion des classes d√©fectueuses dans 'test_1'")
merge_to_defective(test_1)

print("\n‚úÖ Fusion termin√©e avec succ√®s pour model_1 ! üéâ")

compter_elements(train_val_temp_1, True)
compter_elements(test_1, True)
compter_elements(train_val_temp_2, True)
compter_elements(test_2, True)

compter_elements(train_val_temp_1, False)
compter_elements(train_val_temp_2, False)

"""## 3.4)Data augmentation, √©quilibrage des donn√©es et cr√©ation des dossiers train, val des diff√©rents dossiers model_1 et model_2"""

def get_transforms():
    return transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.RandomRotation(20),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0))
    ])

"""#### Augmentation et √©quilibrage des dossiers de test"""

# G√©n√©rer un nouveau nom de fichier unique
def generate_augmented_filename(base_path, prefix="aug", ext=".jpg"):
    i = 0
    while True:
        filename = f"{prefix}_{i}{ext}"
        full_path = os.path.join(base_path, filename)
        if not os.path.exists(full_path):
            return full_path
        i += 1

# Fonction d‚Äôaugmentation
def augment_class_images(class_path, target_count, transform):
    images = [f for f in os.listdir(class_path) if f.lower().endswith((".jpg", ".jpeg", ".png"))]
    current_count = len(images)
    to_generate = target_count - current_count

    print(f"[{os.path.basename(class_path)}] Current: {current_count}, Target: {target_count}, Generating: {to_generate}")

    for _ in tqdm(range(to_generate), desc=f"Augmenting {os.path.basename(class_path)}"):
        img_name = random.choice(images)
        img_path = os.path.join(class_path, img_name)

        try:
            with Image.open(img_path).convert("RGB") as img:
                aug_img = transform(img)
                aug_img = transforms.ToPILImage()(aug_img)
                aug_path = generate_augmented_filename(class_path)
                aug_img.save(aug_path)
        except Exception as e:
           print(f"Error processing {img_path}: {e}")

# Fonction principale
def balance_dataset_with_augmentation(dataset_root):
    class_counts = {}
    class_paths = {}

    for class_name in os.listdir(dataset_root):
        class_path = os.path.join(dataset_root, class_name)
        if not os.path.isdir(class_path):
            continue

        image_files = [f for f in os.listdir(class_path) if f.lower().endswith((".jpg", ".jpeg", ".png"))]
        class_counts[class_name] = len(image_files)
        class_paths[class_name] = class_path

    max_count = max(class_counts.values())
    print(f"Classe la plus fournie : {max_count} images")

    transform = get_transforms()

    for class_name, count in class_counts.items():
        if count < max_count:
            augment_class_images(class_paths[class_name], max_count, transform)
        else:
            print(f"[{class_name}] est d√©j√† √©quilibr√©e.")

balance_dataset_with_augmentation(test_1)
balance_dataset_with_augmentation(test_2)

"""#### Augmentation et √©quilibrage des donn√©es de train_val_temp pour cr√©ation de train et val"""

def augment_to_balance(input_dir):
    transform = get_transforms()

    # Statistiques des classes
    class_counts = {}
    class_images = {}

    for cls in os.listdir(input_dir):
        cls_path = os.path.join(input_dir, cls)
        if not os.path.isdir(cls_path):
            continue
        images = [img for img in os.listdir(cls_path) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if not images:
            continue
        class_counts[cls] = len(images)
        class_images[cls] = images

    if not class_counts:
        print(f"‚ö†Ô∏è Aucune image trouv√©e dans {input_dir}. Traitement ignor√©.")
        return

    max_count = max(class_counts.values())
    target_count = max(max_count, 1500)  # La cible est le max actuel ou 1000, le plus grand des deux
    print(f"\nüìä Classe la plus repr√©sent√©e initialement dans {input_dir} : {max_count} images")
    print(f"üéØ Nombre cible d'images par classe dans {input_dir} : {target_count} images")

    for cls in tqdm(class_images, desc=f"üß™ Augmentation dans {input_dir}", unit="classe"):
        cls_path = os.path.join(input_dir, cls)
        images = class_images[cls]
        current_count = len(images)
        i = 0
        while current_count < target_count:
            img_name = random.choice(images)
            img_path = os.path.join(cls_path, img_name)
            try:
                image = Image.open(img_path).convert("RGB")
                aug_img = transform(image)
                aug_name = f"{os.path.splitext(img_name)[0]}_aug{i}.jpg"
                aug_path = os.path.join(cls_path, aug_name)
                aug_img.save(aug_path)
                current_count += 1
                i += 1
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur sur {img_path} : {e}")
                continue

    print(f"‚úÖ Data augmentation termin√©e pour {input_dir} üéâ")

# üìÅ Ex√©cution sur les deux dossiers :
augment_to_balance(train_val_temp_1)
augment_to_balance(train_val_temp_2)

def split_train_val(input_dir, output_dir, train_ratio=0.8):
    """
    S√©pare les images de chaque classe dans un dossier en 80% train / 20% val.
    :param input_dir: train_val_temp_1 ou train_val_temp_2
    :param output_dir: model_1 ou model_2
    :param train_ratio: proportion des donn√©es pour l'entra√Ænement
    """
    # Cr√©ation des dossiers "train" et "val"
    train_dir = os.path.join(output_dir, 'train')
    val_dir = os.path.join(output_dir, 'val')
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(val_dir, exist_ok=True)

    # Parcours des classes pr√©sentes dans le dossier temporaire
    for class_name in os.listdir(input_dir):
        class_path = os.path.join(input_dir, class_name)
        if not os.path.isdir(class_path):
            continue

        # Liste des images
        images = [img for img in os.listdir(class_path)
                  if img.lower().endswith(('.jpg', '.jpeg', '.png'))]
        random.shuffle(images)

        # Split des images
        split_index = int(len(images) * train_ratio)
        train_images = images[:split_index]
        val_images = images[split_index:]

        # Cr√©ation des dossiers de sortie pour chaque classe
        train_class_dir = os.path.join(train_dir, class_name)
        val_class_dir = os.path.join(val_dir, class_name)
        os.makedirs(train_class_dir, exist_ok=True)
        os.makedirs(val_class_dir, exist_ok=True)

        # D√©placement des images vers le dossier train
        for img in tqdm(train_images, desc=f"üìÅ {class_name} ‚Üí train", unit="img"):
            shutil.move(os.path.join(class_path, img), os.path.join(train_class_dir, img))

        # D√©placement des images vers le dossier val
        for img in tqdm(val_images, desc=f"üìÅ {class_name} ‚Üí val", unit="img"):
            shutil.move(os.path.join(class_path, img), os.path.join(val_class_dir, img))

    # Nettoyage du dossier temporaire une fois le split termin√©
    print(f"\nüßπ Suppression du dossier temporaire : {input_dir}")
    shutil.rmtree(input_dir)
    print(f"‚úÖ Split termin√© pour {output_dir} ! üéâ")


# ‚ú® Application aux deux mod√®les
split_train_val(train_val_temp_1, folder_model_1)
split_train_val(train_val_temp_2, folder_model_2)

compter_elements(train_val_temp_1, False)

compter_elements(train_val_temp_2, False)

compter_elements(folder_model_1, True)
compter_elements(folder_model_1 + '/train', True)
compter_elements(folder_model_1 + '/val', True)
compter_elements(folder_model_1 + '/test_1', True)
compter_elements(folder_model_2, True)
compter_elements(folder_model_2  + '/train', True)
compter_elements(folder_model_2 + '/val', True)
compter_elements(folder_model_2 + '/test_2', True)

# Assuming 'test_1' directory exists as per your provided code.
test_1_dir = folder_model_1 + '/test_1'

def get_random_defective_image(test_dir):
    """
    Returns the path to a random defective image from the test directory.
    """
    defective_dirs = [d for d in os.listdir(test_dir) if d == 'defective' and os.path.isdir(os.path.join(test_dir,d))]
    if not defective_dirs:
        return None  # Handle the case where 'defective' directory doesn't exist

    defective_dir = os.path.join(test_dir, defective_dirs[0])
    images = [f for f in os.listdir(defective_dir) if os.path.isfile(os.path.join(defective_dir, f))]
    if not images:
        return None # Handle the case where the 'defective' directory is empty

    random_image = random.choice(images)
    return os.path.join(defective_dir, random_image)

image_test = get_random_defective_image(test_1_dir)
image_test

"""Notre architecture de dossier et donc bel est con√ßu avec 2 dossiers **model1 et model2** contenant chacun 3 dossiers **train, val et test** contenant eux aussi des classes d'images d√©j√† √©quilibr√©e (defective, unripe et unaffected) pour le model_1 et (spotted, cracked, rotten et bruised) pour le dossier model_2.

# 4) Conception du model

Maintenant passons √† la cr√©ation de notre architecture de classification d'image.
*   **Objectif** : Utiliser 2 models dont l'un laisse la place √† l'autre si il pr√©dit une image comme √©tant 'defective'
*   **Modele utilis√©** : **ViT (Vision Tranformers)**
*   **M√©triques** : Accuracy, precission, recall, f1_score, matrice de confusion
*   **R√©gularisation** : Early stopping, label smoothing, dropout
*   **Optimisation** : AdamW (Adaptive Moment Estimation with Weight Decay), weight decay

## 4.1) Entrainement, validation et test
"""

class Config:
    """
    Configuration pour les mod√®les de classification hi√©rarchique.
    D√©finit les chemins des donn√©es, les noms des classes et les hyperparam√®tres d'entra√Ænement.
    """
    # Paths pour model_1 (classification de niveau sup√©rieur en 3 classes)
    MODEL1 = {
        'train': folder_model_1 + '/train',
        'val': folder_model_1 + '/val',
        'test': folder_model_1 + '/test_1',
        'classes': ['defective', 'unaffected', 'unripe'],
        'num_classes': 3
    }

    # Paths pour model_2 (classification de niveau inf√©rieur en 4 classes, pour les cas 'defective')
    MODEL2 = {
        'train': folder_model_2 + '/train',
        'val': folder_model_2 + '/val',
        'test': folder_model_2 + '/test_2',
        'classes': ['spotted', 'cracked', 'bruised', 'rotten'],
        'num_classes': 4
    }

    # Param√®tres communs
    BATCH_SIZE = 32
    NUM_EPOCHS = 15
    LR = 2e-5
    PATIENCE = 5
    IMG_SIZE = 224
    MODEL_NAME = 'vit_base_patch16_224'
    DROP_RATE = 0.1
    ATTENTION_DROP_RATE = 0.1
    DROP_PATH_RATE = 0.1
    WEIGHT_DECAY = 0.0001
    LABEL_SMOOTHING = 0.1
    MEAN = (0.485, 0.456, 0.406)
    STD = (0.229, 0.224, 0.225)

def get_dataloaders(data_path, batch_size, img_size, mean, std):
    transform = transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])
    dataset = datasets.ImageFolder(data_path, transform=transform)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    return dataloader

def build_vit_model(num_classes):
    model = timm.create_model(
        Config.MODEL_NAME,
        pretrained=True,
        num_classes=num_classes,
        drop_rate=Config.DROP_RATE,
        drop_path_rate=Config.DROP_PATH_RATE,
        attn_drop_rate=Config.ATTENTION_DROP_RATE
    )
    return model

def train_model(model, train_loader, val_loader, num_epochs, save_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    optimizer = optim.AdamW(model.parameters(), lr=Config.LR, weight_decay=Config.WEIGHT_DECAY)
    criterion = nn.CrossEntropyLoss(label_smoothing=Config.LABEL_SMOOTHING)
    best_val_loss = float('inf')
    patience_counter = 0

    for epoch in range(num_epochs):
        model.train()
        train_loss, correct, total = 0, 0, 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(targets).sum().item()
            total += targets.size(0)

        avg_train_loss = train_loss / total
        train_acc = correct / total

        val_loss, val_acc = evaluate_model(model, val_loader)

        print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            torch.save(model.state_dict(), save_path)
        else:
            patience_counter += 1
            if patience_counter >= Config.PATIENCE:
                print("Early stopping")
                break

def evaluate_model(model, loader):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()
    criterion = nn.CrossEntropyLoss()
    total_loss, correct, total = 0, 0, 0
    with torch.no_grad():
        for inputs, targets in loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            total_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(targets).sum().item()
            total += targets.size(0)
    return total_loss / total, correct / total

def test_model(model, loader, class_names):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    model.eval()

    all_preds, all_targets = [], []

    with torch.no_grad():
        for inputs, targets in loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = outputs.max(1)
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(targets.numpy())

    # Rapport texte
    print("\nClassification Report:")
    print(classification_report(all_targets, all_preds, target_names=class_names))

    # Matrice de confusion
    cm = confusion_matrix(all_targets, all_preds)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.title("Matrice de confusion")
    plt.xlabel("Pr√©dit")
    plt.ylabel("V√©rit√©")
    plt.tight_layout()
    plt.show()

def main():
    # Model 1

    train_loader1 = get_dataloaders(Config.MODEL1['train'], Config.BATCH_SIZE, Config.IMG_SIZE, Config.MEAN, Config.STD)
    val_loader1 = get_dataloaders(Config.MODEL1['val'], Config.BATCH_SIZE, Config.IMG_SIZE, Config.MEAN, Config.STD)
    test_loader1 = get_dataloaders(Config.MODEL1['test'], Config.BATCH_SIZE, Config.IMG_SIZE, Config.MEAN, Config.STD)

    model1 = build_vit_model(Config.MODEL1['num_classes'])
    print("üöÄ Entrainement du Model 1")
    train_model(model1, train_loader1, val_loader1, Config.NUM_EPOCHS, "model1_best.pt")
    model1.load_state_dict(torch.load("model1_best.pt"))
    print("üöÄ Test du Model 1")
    test_model(model1, test_loader1, Config.MODEL1['classes'])

    # Model 2
    train_loader2 = get_dataloaders(Config.MODEL2['train'], Config.BATCH_SIZE, Config.IMG_SIZE, Config.MEAN, Config.STD)
    val_loader2 = get_dataloaders(Config.MODEL2['val'], Config.BATCH_SIZE, Config.IMG_SIZE, Config.MEAN, Config.STD)
    test_loader2 = get_dataloaders(Config.MODEL2['test'], Config.BATCH_SIZE, Config.IMG_SIZE, Config.MEAN, Config.STD)

    model2 = build_vit_model(Config.MODEL2['num_classes'])
    print("üöÄ Entrainement du Model 2")
    train_model(model2, train_loader2, val_loader2, Config.NUM_EPOCHS, "model2_best.pt")
    model2.load_state_dict(torch.load("model2_best.pt"))
    print("üöÄ Test du Model 2")
    test_model(model2, test_loader2, Config.MODEL2['classes'])

if __name__ == '__main__':
    main()

image_test = get_random_defective_image(test_1_dir)
image_test

image_test

"""## 4.2) Configuration et essai pour une utilisation ext√©rieur"""

# Configuration
class Config_Pred:
    MODEL_NAME = 'vit_base_patch16_224'
    IMG_SIZE = 224
    MEAN = (0.485, 0.456, 0.406)
    STD = (0.229, 0.224, 0.225)
    MODEL1_CLASSES = ['defective', 'unaffected', 'unripe']
    MODEL2_CLASSES = ['spotted', 'cracked', 'bruised', 'rotten']
    MODEL1_NUM_CLASSES = 3
    MODEL2_NUM_CLASSES = 4

# Fonction de chargement de mod√®le
def load_model(path, num_classes):
    model = create_model(
        Config_Pred.MODEL_NAME,
        pretrained=False,
        num_classes=num_classes
    )
    model.load_state_dict(torch.load(path, map_location=device))
    model = model.to(device)
    model.eval()
    return model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Transformations
transform = transforms.Compose([
    transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(Config.MEAN, Config.STD)
])

# Fonction de pr√©diction hi√©rarchique
def predict_hierarchical(image_path):
    # Charger image
    image = Image.open(image_path).convert("RGB")
    img_tensor = transform(image).unsqueeze(0).to(device)

    # Charger et pr√©dire avec model1
    model1 = load_model("model1_best.pt", Config_Pred.MODEL1_NUM_CLASSES)
    with torch.no_grad():
        output1 = model1(img_tensor)
        pred1 = torch.argmax(output1, dim=1).item()
        class1 = Config_Pred.MODEL1_CLASSES[pred1]

    # Si 'defective', pr√©dire avec model2
    if class1 == "defective":
        model2 = load_model("model2_best.pt", Config_Pred.MODEL2_NUM_CLASSES)
        with torch.no_grad():
            output2 = model2(img_tensor)
            pred2 = torch.argmax(output2, dim=1).item()
            class2 = Config_Pred.MODEL2_CLASSES[pred2]
        return {"level1": class1, "level2": class2}
    else:
        return {"level1": class1, "level2": None}

# Exemple d'utilisation
image_path = image_test
result = predict_hierarchical(image_path)
print("R√©sultat hi√©rarchique:", result)

"""## 4.3) Tel√©chargement des models en local"""

from google.colab import files

# Si les mod√®les sont dans le dossier courant
files.download("model1_best.pt")
files.download("model2_best.pt")



